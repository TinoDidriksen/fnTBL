#!/usr/bin/perl

sub system1 {
  local $comm = shift;
  print stderr "$comm\n" if defined $opt_v;
  system "$comm" unless defined $opt_d;
  if (! defined $opt_d and $?) {
	print stderr "There was an error - exiting\n";
	exit;
  }
}

open f, ">>logfile";
use POSIX qw(strftime);
$now_string = strftime "%a %b %e %H:%M:%S %Y", localtime;
print f $now_string, " $0 @ARGV\n";
close f;

$bin_dir = "/home/fnTBL-1.2/bin";
$exec_dir = "/home/fnTBL-1.2/exec";

use Getopt::Std;

getopts("vdt:F:m:o:R:fT:B:U:NO:D:c:l:");

sub usage {
  print stderr << "EOF";
$0 [-T <training_directory>]
   [-F <lexical_train_param_file>,<contextual_train_param_file>] 
   [-t <noun_common>,<noun_proper>]
   [-R <lex_rule_file>,<context_rule_file>] [-m <most_likely_file>] [-o <out_file>] 
   [-B <bigram_file>] [-U <unigram_file>] 
   <test_file>

where:
 -F <file1>,<file2>          - defines the parameter files for the lexical/contextual tagging
 -m <most_likely_file>       - sets the most likely file; default is word_pos.lexicon
 -o <out_file>               - defines the output file name (default <test_file>.out)
 -t <noun_common>,<noun_proper>
                             - defines the POS symbols for the common noun and proper noun; as default
                               NN is the common noun and NNP is the proper noun
 -R <lex_rule_file>,<context_rule_file>
                             - defines the names for the lexical rules file and the contextual rules file;
                               by default they are lexical.rls and contextual.rls
 -B <bigram_file>            - defines the large file containing bigrams (see documentation)
 -O <opt1>,<opt2>            - additional options to pass to the fnTBL program.
 -U <unigram_file>           - specifies a large file containing unigrams
 -v                          - turns on verbose output
 -T <train_dir>              - defines the directory that holds the training data (the rules, the parameter files, etc)
 <test_file>                 - is the file containing the data to be tagged, 2 columns format - just the words and the truth.

 For more information, run "perldoc pos-apply.prl"
EOF
								;
}

if (@ARGV == ()) {
  usage();
  exit;
}

if (defined $opt_l) {
    if($opt_l eq 'french') {
	$opt_D = "$exec_dir/../trained/frenchPOS";
    } elsif ($opt_l eq 'english') {
	$opt_D = "$exec_dir/../trained/englishPOS";
    } elsif ($opt_l eq 'czech') {
	$opt_D = "$exec_dir/../trained/czechPOS";
    } elsif ($opt_l eq 'basque') {
	$opt_D = "$exec_dir/../trained/basquePOS";
    } elsif ($opt_l eq 'chinese') {
	$opt_D = "$exec_dir/../trained/chinesePOS";
    } elsif ($opt_l eq 'spanish') {
	$opt_D = "$exec_dir/../trained/spanishPOS";
    } elsif ($opt_l eq 'swedish') {
	$opt_D = "$exec_dir/../trained/swedishPOS";
    }
}

@opts = split /,/, $opt_O if defined $opt_O;

if (defined $opt_D) {
  $train_dir = $super_train_dir = $opt_D;
  open f, "$super_train_dir/control_file" || die "The directory $opt_D does not contain the control file - is it corrupted?";
  while (<f>) {
    chomp;
    if (/lexical_param_file (.+)$/) {
      $lexical_param_file = $1;
    } elsif (/context_param_file (.+)$/) {
      $context_param_file = $1;
    } elsif (/lexical_rule_file (.+)$/) {
      $lexical_rule_file = $1;
    } elsif (/context_rule_file (.+)$/) {
      $context_rule_file = $1;
    } elsif (/opt_f (.+)$/) {
      $opt_f = $1;
    } elsif (/opt_B (.+)$/) {
      $opt_B = $1;
    } elsif (/capitalization (.*)$/) {
      if ($1 eq 'yes') {
	$opt_C = 1;
      }
    } elsif (/opt_t (.*)$/) {
      $opt_t = $1;
    }
  }
  $opt_F = "$lexical_param_file,$context_param_file";
  $opt_R = "$super_train_dir/$lexical_rule_file,$super_train_dir/$context_rule_file";
#  print ::stderr "opt_R : $opt_R\n" if defined $opt_v;
  $opt_B = "$super_train_dir/$opt_B";
} elsif (defined $opt_T) {
  # A training directory was provided
  $train_dir = $opt_T;
  unless (defined $opt_F) {
    $opt_F = "$train_dir/tbl.lexical.train.params,$train_dir/tbl.context.pos.params";
  }
  unless (defined $opt_R) {
    $opt_R = "$train_dir/lexical.rls,$train_dir/context.rls";
  }
} else {
  # No training directory was provided - will use the current directory
  print "No training directory was specified - will use the current directory\n" if defined $opt_v;
  $train_dir = ".";
  
  unless (defined $opt_F) {
    $opt_F = "$train_dir/tbl.lexical.train.params,$train_dir/tbl.context.pos.params";
  }
  unless (defined $opt_R) {
    $opt_R = "$train_dir/lexical.rls,$train_dir/context.rls";
  }
}


if (defined $opt_v) {
  $stdout = "-v";
} else {
  $stdout = " >& /dev/null ";
}

if (defined $opt_B) {
  $bigram_file = $opt_B;
} else {
  $bigram_file = "$train_dir/bigrams.dat";
}

@F = split /,/, $opt_F;
@R = split /,/, $opt_R;

# Check which features correspond to the guesses
open f, $F[0]; # Read the parameter file
while (<f>) {
  chomp; 
  @a = split /[ =;]+/;
  $param{$a[0]} = $a[1];

  if (/FILE_TEMPLATE/) {
	chomp;
	s/\s+/ /g;
	s/^\s*//;
	@a = split /[ =;]+/;
	$file = $a[1];
	if ($file =~ /\$/) {
	  $file =~ s/\$\{(.*?)\}/$param{$1}/eg;
	}
	open g, $file;
	$templ = <g>;
	chomp $templ;
	@a = split /\s+/, $templ;
	$guess_pos = $#a-2;
	close g;
	last;
  }
}
close f;

# Check to see if all the files exist (the parameter and rule files)
for ($i=0 ; $i<2 ; $i++) {
  if (!-e $F[$i]) { # if either of the parameter files do not exist
    print stderr "The parameter file $F[$i] does not exist. Please correct the problem and restart\n";
    exit;
  }
  if (! -e $R[$i]) {
    print stderr "The rule file $R[$i] does not exist - please correct the problem and restart\n";
    exit;
  }
}

unless (defined $opt_t) {
  # Search for the spelling of common noun and proper noun in the lexical params file

  $res = `grep SPELLING_OF_NOUNS $F[0]`;
  if ($res ne '') {
    chomp $res;
    $res =~ /SPELLING_OF_NOUNS\s*=\s*(.*?),(.*?)\s*;/;
    $opt_t = "$1,$2";
  } else {
    print stderr "Warning: no spelling of common/proper noun were provided\nand no SPELLING_OF_NOUNS variable is present in $F[0]\n";
    print stderr "Will use the English defaults NN,NNP (and hope for the best...)\n";
    $opt_t = "NN,NNP";
  }
}

@t = split /,/, $opt_t;

$opt_m = "$train_dir/word_pos.lexicon" unless defined $opt_m;

$file = $ARGV[0];
$dir = `dirname $file`;
chomp $dir;

if ($dir eq '.') {
  $dir = $ENV{PWD};
}

# First, we need to run the morphological tagger on the unknown words only (big speedup 
# Select a temporary directory

#  $temp_dir = `tempfile -p fnTBL`;
$temp_dir = randfile("/tmp", "fnTBL", "");
chomp $temp_dir;
if (-e $temp_dir) {
    system "rm $temp_dir";
}
mkdir $temp_dir, 0755;


open f, "$opt_m";
while (<f>) {
  chomp;
  @a = split;
  $seen{$a[0]} = 1;
}

open f, "$file";
open g, ">$temp_dir/unseen_words";
while (<f>) {
  next unless /\S/;
  chomp;
  @a = split;
  print g "$_\n" if !defined $seen{$a[0]};
}
close g;

$temp_unseen_file = "$temp_dir/unseen_words";

if (defined $opt_C) {
  $list_command = "$exec_dir/extract_capitalization.prl -o 1 $train_dir/word_pos.part1.lexicon ";
} else {
  $list_command = "cat ";
}

system1 "$list_command $temp_unseen_file | perl -ape '\$F[$guess_pos] = \"-\" unless defined \$F[$guess_pos]; \$_=\"\@F[0..\$\#F-1] - \$F[-1]\\n\" if /\\S/' - | $exec_dir/most_likely_tag.prl -l $opt_m -p '0=>$guess_pos' -t $opt_t - > $temp_dir/$file.init";

$lexical_params = `basename $F[0]`;
chomp $lexical_params;
$lexical_params .= "0";

open f, $F[0];
open g, ">$temp_dir/$lexical_params";
$seen_constraint = 0;
while (<f>) {
  if (/EMPTY_LINES_ARE_SEPARATORS/) {
    print g "EMPTY_LINES_ARE_SEPARATORS = 0;\n";
  } elsif (/CONSTRAINTS_FILE/) {
    # No constraints
  } elsif (/MAIN\s*=/) {
	print g "MAIN = $train_dir;\n";
  } elsif (/LARGE_WORD_VOCABULARY/) {
    if (defined $opt_U) {
      print g "LARGE_WORD_VOCABULARY = $opt_U\n";
    } else {
      print g "LARGE_WORD_VOCABULARY = $train_dir/BIGWORDLIST;\n";
    }
  } elsif (/COOCCURRENCE_CONFIGURATION_FILE/) {
    print g "COOCCURRENCE_CONFIGURATION_FILE = $temp_dir/bigrams.test.templ;\n";
  } elsif (/LOGFILE/) {
    print g "LOGFILE = logfile;\n";
  } elsif (/\$\{MAIN\}/) {
    s/\$\{MAIN\}/$train_dir/g;
    print g;
  } else {
    print g;
  }
}

# unless ($seen_constraint) {
#   print g "CONSTRAINTS_FILE = $temp_dir/constraints.test.fake.templ;\n";
# }

close g;

# Create 2 temporary files
print stderr "Creating $temp_dir/bigrams.test.templ\n" if defined $opt_v;
open g, "> $temp_dir/bigrams.test.templ";
print g "word_0 word_1 $temp_dir/bigrams.small.dat\n",
  "word_-1 word_0 $temp_dir/bigrams.small.dat\n";
close g;
# Extract the bigrams that have at least one of the words from the bigram cooccurrence rules
# in them (otherwise, they don't contribute at all to the application of the system).
open g, "$R[0]";
while (<g>) {
  if (/\^\^-?\d+=(.*?) /) {
    $selected{$1} = 1;
  }
}
close g;

print stderr "bigram file = $bigram_file\n" if defined $opt_v;
open g, $bigram_file;
open h, "> $temp_dir/bigrams.small.dat";
while (<f>) {
  chomp;
  @a = split;
  if ($selected{$a[0]} or $selected{$a[1]}) {
    print h "$_\n";
  }
}

# open g, "grep '\\^\\^' $R[0] |";
# open h, "| sort -u >/tmp/tmp.wrds";
# while (<g>) {
#   /word\^\^-?\d+=(.*?) /;
#   print h "$1\n";
# }
# close g;
# close h;

# system1 "sort -u $bigram_file | join - /tmp/tmp.wrds > /tmp/tmp1";
# system1 "sort -u -k 2,2 $bigram_file | join -1 2 - /tmp/tmp.wrds | cat - /tmp/tmp1 > bigrams.small.dat";
# system1 "rm /tmp/tmp.wrds /tmp/tmp1";

# print stderr "Creating $temp_dir/constraints.lexical.test.templ.\n" if defined $opt_v;
# open g, "> $temp_dir/constraints.lexical.test.templ";
# print g "word tpos $train_dir/word_pos.fake.lexicon\n";
# close g;

system1 "$bin_dir/fnTBL $temp_dir/$file.init $R[0] -F $temp_dir/$lexical_params -o $temp_dir/$file.lexical".
  (defined $opts[0] ? " $opts[0]" : "").
  " $stdout";
$out = defined $opt_o ? $opt_o : "$file.out";

# Add the results to the list of known tags

system1 "$exec_dir/mcreate_lexicon.prl -d '0=>$guess_pos' $temp_dir/$file.lexical > $temp_dir/word_pos.additional";

system1 "cat $train_dir/word_pos.lexicon $temp_dir/word_pos.additional > $temp_dir/word_pos.new_lexicon";

system1 "$list_command $file | perl -ape 'next unless /\\S/; \$F[$guess_pos] = \"-\" unless defined \$F[$guess_pos]; \$_=\"\@F[0..\$\#F-1] - \$F[-1]\\n\" if /\\S/' - | $exec_dir/most_likely_tag.prl -l $temp_dir/word_pos.new_lexicon -p '0=>$guess_pos' -t $opt_t - > $temp_dir/$file.lexical";

$context_params = `basename $F[1]`;
chomp $context_params;
$context_params .= "1";
open f, $F[1];

open g, ">$temp_dir/$context_params";
$seen_constraint = 0;
while (<f>) {
  if (/EMPTY_LINES_ARE_SEPARATORS/) {
	print g "EMPTY_LINES_ARE_SEPARATORS = 1;\n";
  } elsif (/^\s*MAIN\s*=/) {
	print g "MAIN = $train_dir;\n";
  } elsif (/CONSTRAINTS_FILE/) {
	print g "CONSTRAINTS_FILE = $temp_dir/constraints.context.test.templ;\n";
	$seen_constraint = 1;
#   } elsif (/COOCCURRENCE_CONFIGURATION_FILE/) {
# 	print g "COOCCURRENCE_CONFIGURATION_FILE = bigrams.test.templ;\n";
  } elsif (/\$\{MAIN\}/) {
	s/\$\{MAIN\}/$train_dir/;
	print g;
  } else {
	print g;
  }
}
unless ($seen_constraint) {
  print g "CONSTRAINTS_FILE = $temp_dir/constraints.context.test.templ;\n";
}
close g;

print stderr "Creating $temp_dir/constraint.context.test.templ.\n" if defined $opt_v;
open g, "> $temp_dir/constraints.context.test.templ";

if (defined $opt_f) {
  print g "word tpos $train_dir/word_pos.$opt_f.lexicon\n";
} elsif (defined $opt_m) {
  print g "word tpos $train_dir/word_pos.10.lexicon\n";
} else {
  print g "word tpos $train_dir/word_pos.10.lexicon\n";
}
close g;

if (defined $opt_c) {
    open f, $R[1];
    $a = $R[1];
    $a =~ s/.rls/-$opt_c.rls/;
    open g, ">$a";
    while (<f>) {
	unless(/GOOD:0 / and /SCORE:(\d+) / and $1<$opt_c) {
	    print g;
	}
    }
    close g;
    $R[1] = $a;
}

system1 "$bin_dir/fnTBL $temp_dir/$file.lexical $R[1] -F $temp_dir/$context_params -o $out".
  (defined $opts[1] ? " $opts[1]" : "").
  " $stdout";

#system1 "rm $file.init $file.lexical bigrams.test.templ bigrams.small.dat $lexical_params $context_params constraints.context.test.templ constraints.lexical.test.templ" unless defined $opt_N;
system "rm -rf $temp_dir" unless defined $opt_N;

sub randfile
{
   my($dir,$pre,$suf) = @_;
   my($f);
   while (1) {
      $f = int(rand(1000000));
      $fname = $pre . $f . $suf;
      if (!open(xxx, "<$dir/$fname")) {
         return "$dir/$fname";
      }
   }
}

__END__

# Some documentation

=head1 Applying the fnTBL POS tagger

I<pos-apply.prl> - this program applies the rules generated by fnTBL POS tagger to
new data; this data needs to be in a particular 2/3 column format.

=head1 Calling Method

pos-apply.prl <options> I<test-data>

=head1 Options:

=over 4

=item B<-T> I<directory>

This options defines the directory that contains the training files (the rule files, 
the parameter files, all the other files needed for the fnTBL to run properly). If you
are running the script I<pos-apply> from a different directory than the one where these
files reside, you will need to specify this flag.

=item B<-F> I<file1>,I<file2>

This options defines the lexical, respective contextual, parameter files. If you plan to use
the ones provided (for instance, the ones from trained/englishPOS), and you specified the 
training directory (using the B<-T> flag), then specifying this files is not necessary.

=item B<-m> I<most-likely file>

This option can be used to specify the file containing the most-likely associations (for each
word, provides a list of the corresponding POS tags, in the order of likelihood). If the B<-T>
flag was specified, and the regular file is to be used, this parameter can be omitted. Otherwise,
it is required.

=item B<-N>

If this flag is set, the temporary files will not be deleted after the
script finishes; by default, these files are deleted.

=item B<-o> I<out_file>

This option specifies the output file. By default, the output file is
I<test_file.out>

=item B<-t> I<noun_common>,I<noun_proper>

This option is used to specify the spelling of the common noun and that of the proper noun -- 
for English, the values are NN and NNP. If this flag is not specified, the script will search 
for it in the I<lexical_train_params_file> - either the one specified by using the B<-F> flag,
or the default file (tbl.lexical.train.params), in a parameter variable called SPELLING_OF_NOUNS; if even
that variable is not specified, a warning message will be printed -- announcing that the default 
English values will be used. 

Bad things can happen if the variables are not set to the proper values (such as the program giving 
very bad results).

=item B<-B> I<bigram_file>

This option can be used to specify a large file containing word bigrams, one bigram per line. If
not defined, the file bigrams.dat from the training directory will be used. The main purpose of 
this file is to help in the lexical tagging (see the online or postscript documentation for a more
detailed explanation).

=item B<-O> I<opt1>,I<opt2>

If additional flags are needed to be passed to the I<fnTBL> program, the flag B<-O> comes to help. 
Following it, two sets of arguments, separated by commas, are to be provided; if necessary, enclose
the commands between quotes (e.g. B<-O> 'C<-p> C<-t> lexical.tree','C<-p> C<-t> context.tree').

=item B<-U> I<unigram_file>

This option can be used to specify a large file containing word unigrams, one word per line. If
not defined, the file BIGWORDLIST from the training directory will be used. The main purpose of 
this file is to help in the lexical tagging (see the online or postscript documentation for a more
detailed explanation).

=item B<-v>

The program will output various debugging messages.

=item <test_file>

This is the test file on which the program will be run. It needs to be in either a 1 or 2 column 
format. In the 1-column format, each line should have just a word; sentences should be separated 
by an empty lines. In the 2-column format, the first column should be the word and the second should 
be the true part of speech associated with the word on the first position. The columns should be 
separated by white space (spaces, tabs, etc).

=item The output

The output will be done either in the file specified by the B<-o> flag, or, by default, in a 
file called I<<test_file>.out> (where I<test_file> is the specified test file). It will be either
in 2 column or 3 column format (depending on whether the initial test file had 2, respectively 3, 
columns). The second column will always have the POS assigned by fnTBL; the third will optionally 
have the true POS present (if any) in the I<test_file>.

=back

=cut

